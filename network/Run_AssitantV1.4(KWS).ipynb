{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c3feae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:42.740271Z",
     "start_time": "2022-05-04T19:13:14.935357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/.local/lib/python3.7/site-packages/h5py/__init__.py:40: UserWarning: h5py is running against HDF5 1.10.6 when it was built against 1.10.4, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c6af7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:45.778078Z",
     "start_time": "2022-05-04T19:13:42.773836Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "unable to open file: libtensorflow_io.so, from paths: ['/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io.so']\ncaused by: ['/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io.so: cannot open shared object file: No such file or directory']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mplugin_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtensorflow_io_plugins.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"unable to open file: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}, from paths: {}\\ncaused by: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io_plugins.so']\ncaused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io_plugins.so'\"]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2396/3161778343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 将一段频谱图转成梅尔频谱\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_melcepstrum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# (124, 129, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"tensorflow_io\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv0\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/api/v0/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# tensorflow_io.core.python.ops is implicitly imported (along with file system)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Note: load libtensorflow_io.so imperatively in case of statically linking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtensorflow_io.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mplugin_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtensorflow_io.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     68\u001b[0m     raise NotImplementedError(\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"unable to open file: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}, from paths: {}\\ncaused by: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unable to open file: libtensorflow_io.so, from paths: ['/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io.so']\ncaused by: ['/home/pi/.local/lib/python3.7/site-packages/tensorflow_io-0.17.0-py3.7-linux-armv7l.egg/tensorflow_io/core/python/ops/libtensorflow_io.so: cannot open shared object file: No such file or directory']"
     ]
    }
   ],
   "source": [
    "import tensorflow_io as tfio\n",
    "\n",
    "# 将一段频谱图转成梅尔频谱\n",
    "def get_melcepstrum(spectrogram):\n",
    "    # (124, 129, 1)\n",
    "    melspectrogram = tfio.audio.melscale(\n",
    "    spectrogram, rate=16000, mels=40, fmin=0, fmax=8000)\n",
    "    melspectrogram = melspectrogram[..., tf.newaxis]# 新增一个aixs\n",
    "    return melspectrogram\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 16000\n",
    "  waveform = waveform[:input_len]\n",
    "  zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=1024, frame_step=512)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  # Batch Size，样本数（时间序列长度/frame_step=125），频率点数(样本窗口/2)，通道\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  #melspectrogram = melspectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc0464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:45.789485Z",
     "start_time": "2022-05-04T19:13:45.789368Z"
    }
   },
   "outputs": [],
   "source": [
    "import apa102\n",
    "\n",
    "PIXELS_N = 3\n",
    "\n",
    "rgb_led = apa102.APA102(num_led=PIXELS_N)\n",
    "\n",
    "#RGB\n",
    "\n",
    "rgb_led.set_pixel(0, 0, 0, 0) #没有信号\n",
    "\n",
    "rgb_led.set_pixel(0, 0, 0, 0) #有打印正常声音信号\n",
    "\n",
    "rgb_led.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d3fdd",
   "metadata": {},
   "source": [
    "# 以上为每次启动需要执行的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53d9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:45.798631Z",
     "start_time": "2022-05-04T19:13:45.798507Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    cap.set(3,640) # adjust width\n",
    "    cap.set(4,480) # adjust height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac2ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:45.808378Z",
     "start_time": "2022-05-04T19:13:45.808248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import datetime\n",
    "RESPEAKER_RATE = 16000\n",
    "RESPEAKER_CHANNELS = 2\n",
    "RESPEAKER_WIDTH = 2\n",
    "# run getDeviceInfo.py to get index\n",
    "RESPEAKER_INDEX = 0  # refer to input device id\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1 #录音一秒\n",
    "WAVE_OUTPUT_FILENAME = \"./dataset/output_one_channel\"\n",
    "\n",
    "model = tf.keras.models.load_model('./SLA3dPrintAssitant For Raspi.h5')#加载模型\n",
    "\n",
    "for i in range(0,3*60*60):#录音3h，生成3*3600个wav文件\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "                rate=RESPEAKER_RATE,\n",
    "                format=p.get_format_from_width(RESPEAKER_WIDTH),\n",
    "                channels=RESPEAKER_CHANNELS,\n",
    "                input=True,\n",
    "                input_device_index=RESPEAKER_INDEX,)\n",
    "    a=np.array([])\n",
    "    frames = [] \n",
    "        \n",
    "    while(1):\n",
    "        try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "            #读取1秒 16000个点\n",
    "            for i in range(0, int(RESPEAKER_RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "                # extract channel 0 data from 2 channels, if you want to extract channel 1, please change to [1::2]\n",
    "                #a = np.fromstring(data,dtype=np.int16)[0::2]\n",
    "                a = np.append(a,np.fromstring(data,dtype=np.int16)[0::2])\n",
    "            #print(\"Wave shape:\",a.shape)\n",
    "            spectrogram = get_spectrogram(a)#信号转频谱\n",
    "            del a\n",
    "            a=np.array([])\n",
    "            #print(\"spectrogram shape:\",spectrogram.shape)\n",
    "            melcepstrum = get_melcepstrum(spectrogram)#频谱转梅尔频谱\n",
    "            #print(\"Model Input melcepstrum shape:\",melcepstrum.shape)\n",
    "            #print(\"Model Input melcepstrum Type:\",type(melcepstrum))\n",
    "            melcepstrum = tf.reshape(melcepstrum, (-1, 30, 40, 1))#调整维度，满足输入维度\n",
    "            y_pred = np.argmax(model.predict(melcepstrum), axis=1) #0:Good 1:Background\n",
    "            #print(y_pred)\n",
    "            if(y_pred[0]==0):#有打印正常声音信号\n",
    "                rgb_led.set_pixel(0, 0, 20, 0) #有打印正常声音信号\n",
    "                rgb_led.show()\n",
    "            else:\n",
    "                rgb_led.set_pixel(0, 20, 0, 0) #没有信号\n",
    "                rgb_led.show()\n",
    "        except KeyboardInterrupt:\n",
    "            vc.release()\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "            print(\"SLA 3d Printer Assitant Stop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145e39a",
   "metadata": {},
   "source": [
    "# 以下为主进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32cb08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T19:13:45.817270Z",
     "start_time": "2022-05-04T19:13:45.817141Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import datetime\n",
    "RESPEAKER_RATE = 16000\n",
    "RESPEAKER_CHANNELS = 2\n",
    "RESPEAKER_WIDTH = 2\n",
    "# run getDeviceInfo.py to get index\n",
    "RESPEAKER_INDEX = 0  # refer to input device id\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1 #录音一秒\n",
    "WAVE_OUTPUT_FILENAME = \"./dataset/output_one_channel\"\n",
    "\n",
    "model = tf.keras.models.load_model('./KWS on Raspi.h5')#加载模型KWS on Raspi.h5 |SLA3dPrintAssitant For Raspi.h5\n",
    "\n",
    "def kws_nerual_network():#神经网络识别声音\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "                rate=RESPEAKER_RATE,\n",
    "                format=p.get_format_from_width(RESPEAKER_WIDTH),\n",
    "                channels=RESPEAKER_CHANNELS,\n",
    "                input=True,\n",
    "                input_device_index=RESPEAKER_INDEX,)\n",
    "    a=np.array([])\n",
    "    frames = [] \n",
    "        \n",
    "    while(1):\n",
    "        try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "            #读取1秒 16000个点\n",
    "            for i in range(0, int(RESPEAKER_RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "                # extract channel 0 data from 2 channels, if you want to extract channel 1, please change to [1::2]\n",
    "                #a = np.fromstring(data,dtype=np.int16)[0::2]\n",
    "                a = np.append(a,np.fromstring(data,dtype=np.int16)[0::2])\n",
    "            #print(\"Wave shape:\",a.shape)\n",
    "            spectrogram = get_spectrogram(a)#信号转频谱\n",
    "            del a\n",
    "            a=np.array([])\n",
    "            #print(\"spectrogram shape:\",spectrogram.shape)\n",
    "            melcepstrum = get_melcepstrum(spectrogram)#频谱转梅尔频谱\n",
    "            #print(\"Model Input melcepstrum shape:\",melcepstrum.shape)\n",
    "            #print(\"Model Input melcepstrum Type:\",type(melcepstrum))\n",
    "            melcepstrum = tf.reshape(melcepstrum, (-1, 30, 40, 1))#调整维度，满足输入维度\n",
    "            y_pred = np.argmax(model.predict(melcepstrum), axis=1) #0:Good 1:Background\n",
    "            print(y_pred)\n",
    "            # R G B\n",
    "            if(y_pred[0]==0):#down\n",
    "                rgb_led.set_pixel(0, 5, 0, 0)\n",
    "                #widgets.Label(value=\"Good\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==1):#go\n",
    "                rgb_led.set_pixel(0, 0, 5, 0) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==2):#left\n",
    "                rgb_led.set_pixel(0, 0, 0, 5) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==3):#no\n",
    "                rgb_led.set_pixel(1, 5, 0, 0) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==4):#right\n",
    "                rgb_led.set_pixel(1, 0, 5, 0) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==5):#stop\n",
    "                rgb_led.set_pixel(1, 0, 0, 5) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==6):#up\n",
    "                rgb_led.set_pixel(2, 5, 0, 0) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "            elif(y_pred[0]==7):#yes\n",
    "                rgb_led.set_pixel(2, 0, 5, 0) \n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "        except KeyboardInterrupt:\n",
    "            vc.release()\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "            print(\"SLA 3d Printer Assitant Stop!\")\n",
    "\n",
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    cap.set(3,160) # adjust width\n",
    "    cap.set(4,80) # adjust height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread1 = threading.Thread(target=view, args=(stopButton,))\n",
    "thread2 = threading.Thread(target=kws_nerual_network,)\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f83d60",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-04T18:55:37.285Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.Label(value=\"Background1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb530f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
