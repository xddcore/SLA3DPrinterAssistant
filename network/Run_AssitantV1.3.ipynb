{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3feae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:52:10.361851Z",
     "start_time": "2022-04-28T09:51:44.613578Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6af7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:52:20.388906Z",
     "start_time": "2022-04-28T09:52:10.410440Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_melcepstrum(spectrogram):\n",
    "    #1.频率转梅尔频率\n",
    "    #2.梅尔频率下，滤波器线性排列n个滤波器\n",
    "    #3.把滤波器梅尔频率转回频率，得到的滤波器三角形底边长就是逐渐增长的\n",
    "    #4.得到离散的三角形\n",
    "    #5.将每个离散的三角形滤波器*频谱图，得到梅尔频谱\n",
    "    #PS: 无论傅里叶变化得到的频谱图还是梅尔频谱，w轴本质都是个尺度问题。频谱图有自己的尺度，梅尔频谱有自己的尺度。\n",
    "    #每个滤波器三角形是重叠1/2的，这意味着，当我们在[0,513]设置40个距离相等的梅尔频率点时，我们得到了80个可选的三角形滤波器。\n",
    "    #但是由于我们只需要40个。所以我们从左到右选择40个。\n",
    "    #这40个三角形滤波器的频率范围为0-1848Hz。当滤波器数量为80个时，频率范围与上相同，但是滤波器\n",
    "    #更加密集。每个滤波器代表的频率范围更小。\n",
    "    #参数作用 当最低频率为0 最高频率(不能超过采样率/2)为8000Hz时\n",
    "    #滤波器数量越多，被选中的范围也越大\n",
    "    #当滤波器数量为40时，被提取的频率点范围为0-1848Hz 接近人耳听力范围\n",
    "    #当滤波器数量不变，被选中的范围缩小时，被提取的频率点范围缩小\n",
    "    low_freq_mel = 0 #低频点hz\n",
    "    high_freq_mel = 512 #高频点hz（当对于STFT来说，0-8000Hz 对应着0-513个频率点\n",
    "    high_freq_mel = (2595 * np.log10(1 + (high_freq_mel/2) / 700)) #根据公式将频率转换为梅尔频率\n",
    "    nfilter = 40 #梅尔滤波器数量\n",
    "    hz_points = np.array([])#梅尔滤波器三角形 左端点 中间点 右端点\n",
    "    hz_points_center  = np.array([])#每个梅尔滤波器中间点坐标\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilter+2) #生成距离相等的梅尔频率点\n",
    "\n",
    "    # 将生成的梅尔频率转换成频率点\n",
    "    hz_points_1 = (700 * (10**(mel_points / 2595) - 1)) #不含中间点\n",
    "    for i in range(0,int(hz_points_1.shape[0]-1)):\n",
    "        hz_points_center = np.append(hz_points_center, np.floor((hz_points_1[i]+hz_points_1[i+1])/2))\n",
    "        \n",
    "\n",
    "    hz_points = np.append(hz_points,np.floor(hz_points_1))\n",
    "    #hz_points = np.append(hz_points,hz_points_center)\n",
    "    hz_points = np.sort(hz_points) #所有滤波器三角形坐标(左端坐标，中间坐标，右端坐标)由小到大排列\n",
    "\n",
    "    mel_filter = np.zeros([nfilter, 513])#存储滤波器的系数\n",
    "\n",
    "    for n_mel_filter in range(1, nfilter + 1): #以中心坐标标记滤波器，第一个滤波器中心坐标1，第二个滤波器中心坐标3...\n",
    "        mel_filter_left = int(hz_points[n_mel_filter - 1])   # 一个滤波器左端坐标\n",
    "        mel_filter_center = int(hz_points[n_mel_filter])             # 一个滤波器中心坐标\n",
    "        mel_filter_right = int(hz_points[n_mel_filter + 1])    # 一个滤波器右端坐标\n",
    "        for k in range(mel_filter_left, mel_filter_center): #计算每个滤波器的系数 \n",
    "            mel_filter[n_mel_filter - 1, k] = (k - hz_points[n_mel_filter - 1]) / (hz_points[n_mel_filter] - hz_points[n_mel_filter - 1])\n",
    "        for k in range(mel_filter_center, mel_filter_right):\n",
    "            mel_filter[n_mel_filter - 1, k] = (hz_points[n_mel_filter + 1] - k) / (hz_points[n_mel_filter + 1] - hz_points[n_mel_filter])\n",
    "\n",
    "    #依次将每个T时刻的频谱转换为梅尔频谱，并拼接\n",
    "    for i,spectrogram_1t in enumerate(tf.squeeze(spectrogram, axis=-1).numpy().T):\n",
    "        melcepstrum = np.dot(spectrogram_1t, mel_filter.T)\n",
    "        #melcepstrum = np.where(melcepstrum == 0, np.finfo(float).eps, melcepstrum)  # Numerical Stability\n",
    "        #melcepstrum = 20 * np.log10(melcepstrum)  # dB\n",
    "        melcepstrum = melcepstrum[:,np.newaxis]\n",
    "        if i == 0:\n",
    "            melcepstrum_ = melcepstrum\n",
    "        else:\n",
    "            melcepstrum_ = np.append(melcepstrum_,melcepstrum,axis=1)\n",
    "    melcepstrum_tf = tf.convert_to_tensor(melcepstrum_.T)\n",
    "    melcepstrum_tf = melcepstrum_tf[..., tf.newaxis]# 新增一个aixs\n",
    "    \n",
    "    #打印梅尔频谱图\n",
    "    #plt.figure()\n",
    "    #plt.imshow(tf.math.log(tf.squeeze(melcepstrum_tf, axis=-1)).numpy())\n",
    "    \n",
    "    return melcepstrum_tf\n",
    "        \n",
    "def get_spectrogram(waveform):\n",
    "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 16000\n",
    "  waveform = waveform[:input_len]\n",
    "  zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "  # clips are of the same length.\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  #f频率数组，时间数组，STFT结果\n",
    "  equal_length_np = equal_length.numpy()\n",
    "  [f,t,spectrogram]=signal.spectral.spectrogram(equal_length.numpy(),nperseg=512,nfft=1024,detrend=False)\n",
    "  #spectrogram = tf.signal.stft(\n",
    "  #    equal_length, frame_length=1024, frame_step=512)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  # Batch Size，样本数（时间序列长度/frame_step=125），频率点数(样本窗口/2)，通道\n",
    "    #显示波形和频谱\n",
    "  spectrogram = spectrogram[:,:30]\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  \n",
    "  #打印频谱图\n",
    "  #plt.figure()\n",
    "  #plt.imshow(tf.math.log(tf.squeeze(spectrogram, axis=-1)).numpy().T)\n",
    "  #display.display(display.Audio(waveform, rate=16000))\n",
    "  \n",
    "  '''\n",
    "  plt.figure()\n",
    "  plt.imshow(tf.math.log(spectrogram).numpy())\n",
    "  #plt.figure()\n",
    "  # 把之前加在梅尔频谱最后的通道维度删除\n",
    "  #plt.imshow(tf.math.log(tf.squeeze(melspectrogram, axis=-1)).numpy())\n",
    "  #plt.imshow(tf.math.log(spectrogram.numpy())\n",
    "  print('Waveform shape:', waveform.shape)\n",
    "  print('Padding Waveform shape:',equal_length_np.shape)\n",
    "  print('Spectrogram shape:', spectrogram.shape)\n",
    "  #print('melspectrogram shape:', melspectrogram.shape)\n",
    "  print('Audio playback')\n",
    "  display.display(display.Audio(waveform, rate=16000))\n",
    "  '''\n",
    "\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc0464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:52:20.445998Z",
     "start_time": "2022-04-28T09:52:20.398999Z"
    }
   },
   "outputs": [],
   "source": [
    "import apa102\n",
    "\n",
    "PIXELS_N = 3\n",
    "\n",
    "rgb_led = apa102.APA102(num_led=PIXELS_N)\n",
    "\n",
    "#RGB\n",
    "\n",
    "rgb_led.set_pixel(0, 0, 0, 0) #没有信号\n",
    "\n",
    "rgb_led.set_pixel(0, 0, 0, 0) #有打印正常声音信号\n",
    "\n",
    "rgb_led.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d3fdd",
   "metadata": {},
   "source": [
    "# 以上为每次启动需要执行的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53d9ff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-28T09:12:00.216Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    cap.set(3,640) # adjust width\n",
    "    cap.set(4,480) # adjust height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac2ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:14:05.276042Z",
     "start_time": "2022-04-28T09:13:03.643649Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import datetime\n",
    "RESPEAKER_RATE = 16000\n",
    "RESPEAKER_CHANNELS = 2\n",
    "RESPEAKER_WIDTH = 2\n",
    "# run getDeviceInfo.py to get index\n",
    "RESPEAKER_INDEX = 0  # refer to input device id\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1 #录音一秒\n",
    "WAVE_OUTPUT_FILENAME = \"./dataset/output_one_channel\"\n",
    "\n",
    "model = tf.keras.models.load_model('./SLA3dPrintAssitant For Raspi.h5')#加载模型\n",
    "\n",
    "for i in range(0,3*60*60):#录音3h，生成3*3600个wav文件\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "                rate=RESPEAKER_RATE,\n",
    "                format=p.get_format_from_width(RESPEAKER_WIDTH),\n",
    "                channels=RESPEAKER_CHANNELS,\n",
    "                input=True,\n",
    "                input_device_index=RESPEAKER_INDEX,)\n",
    "    a=np.array([])\n",
    "    frames = [] \n",
    "        \n",
    "    while(1):\n",
    "        try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "            #读取1秒 16000个点\n",
    "            for i in range(0, int(RESPEAKER_RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "                # extract channel 0 data from 2 channels, if you want to extract channel 1, please change to [1::2]\n",
    "                #a = np.fromstring(data,dtype=np.int16)[0::2]\n",
    "                a = np.append(a,np.fromstring(data,dtype=np.int16)[0::2])\n",
    "            #print(\"Wave shape:\",a.shape)\n",
    "            spectrogram = get_spectrogram(a)#信号转频谱\n",
    "            del a\n",
    "            a=np.array([])\n",
    "            #print(\"spectrogram shape:\",spectrogram.shape)\n",
    "            melcepstrum = get_melcepstrum(spectrogram)#频谱转梅尔频谱\n",
    "            #print(\"Model Input melcepstrum shape:\",melcepstrum.shape)\n",
    "            #print(\"Model Input melcepstrum Type:\",type(melcepstrum))\n",
    "            melcepstrum = tf.reshape(melcepstrum, (-1, 30, 40, 1))#调整维度，满足输入维度\n",
    "            y_pred = np.argmax(model.predict(melcepstrum), axis=1) #0:Good 1:Background\n",
    "            #print(y_pred)\n",
    "            if(y_pred[0]==0):#有打印正常声音信号\n",
    "                rgb_led.set_pixel(0, 0, 20, 0) #有打印正常声音信号\n",
    "                rgb_led.show()\n",
    "            else:\n",
    "                rgb_led.set_pixel(0, 20, 0, 0) #没有信号\n",
    "                rgb_led.show()\n",
    "        except KeyboardInterrupt:\n",
    "            vc.release()\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "            print(\"SLA 3d Printer Assitant Stop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145e39a",
   "metadata": {},
   "source": [
    "# 以下为主进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32cb08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:52:41.974757Z",
     "start_time": "2022-04-28T09:52:34.508174Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import datetime\n",
    "RESPEAKER_RATE = 16000\n",
    "RESPEAKER_CHANNELS = 2\n",
    "RESPEAKER_WIDTH = 2\n",
    "# run getDeviceInfo.py to get index\n",
    "RESPEAKER_INDEX = 0  # refer to input device id\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1 #录音一秒\n",
    "WAVE_OUTPUT_FILENAME = \"./dataset/output_one_channel\"\n",
    "\n",
    "model = tf.keras.models.load_model('./SLA3dPrintAssitant For Raspi.h5')#加载模型\n",
    "\n",
    "def kws_nerual_network():#神经网络识别声音\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "                rate=RESPEAKER_RATE,\n",
    "                format=p.get_format_from_width(RESPEAKER_WIDTH),\n",
    "                channels=RESPEAKER_CHANNELS,\n",
    "                input=True,\n",
    "                input_device_index=RESPEAKER_INDEX,)\n",
    "    a=np.array([])\n",
    "    frames = [] \n",
    "        \n",
    "    while(1):\n",
    "        try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "            #读取1秒 16000个点\n",
    "            for i in range(0, int(RESPEAKER_RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "                # extract channel 0 data from 2 channels, if you want to extract channel 1, please change to [1::2]\n",
    "                #a = np.fromstring(data,dtype=np.int16)[0::2]\n",
    "                a = np.append(a,np.fromstring(data,dtype=np.int16)[0::2])\n",
    "            #print(\"Wave shape:\",a.shape)\n",
    "            spectrogram = get_spectrogram(a)#信号转频谱\n",
    "            del a\n",
    "            a=np.array([])\n",
    "            #print(\"spectrogram shape:\",spectrogram.shape)\n",
    "            melcepstrum = get_melcepstrum(spectrogram)#频谱转梅尔频谱\n",
    "            #print(\"Model Input melcepstrum shape:\",melcepstrum.shape)\n",
    "            #print(\"Model Input melcepstrum Type:\",type(melcepstrum))\n",
    "            melcepstrum = tf.reshape(melcepstrum, (-1, 30, 40, 1))#调整维度，满足输入维度\n",
    "            y_pred = np.argmax(model.predict(melcepstrum), axis=1) #0:Good 1:Background\n",
    "            #print(y_pred)\n",
    "            if(y_pred[0]==0):#有打印正常声音信号\n",
    "                rgb_led.set_pixel(0, 0, 20, 0) #有打印正常声音信号\n",
    "                #widgets.Label(value=\"Good\")\n",
    "                rgb_led.show()\n",
    "            else:\n",
    "                rgb_led.set_pixel(0, 20, 0, 0) #没有信号\n",
    "                #widgets.Label(value=\"Background\")\n",
    "                rgb_led.show()\n",
    "        except KeyboardInterrupt:\n",
    "            vc.release()\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "            print(\"SLA 3d Printer Assitant Stop!\")\n",
    "\n",
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    cap.set(3,160) # adjust width\n",
    "    cap.set(4,80) # adjust height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread1 = threading.Thread(target=view, args=(stopButton,))\n",
    "thread2 = threading.Thread(target=kws_nerual_network,)\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f83d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T09:50:06.061513Z",
     "start_time": "2022-04-28T09:50:05.946600Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.Label(value=\"Background1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb530f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
